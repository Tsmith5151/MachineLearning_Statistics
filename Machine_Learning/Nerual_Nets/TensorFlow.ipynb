{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Data...\n",
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "headers = ['age','workclass','fnlwgt','education','edu_num','marital_status',\n",
    "           'occupation','relationship','race','sex','cap_gain','cap_loss',\n",
    "           'work_hrs_weekly','country','income']\n",
    "try:\n",
    "    print('Getting Data...')\n",
    "    df_train_raw = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',names=headers)\n",
    "    df_test_raw = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test',names=headers)\n",
    "    print('Data Loaded Successfully!')\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age                32561 non-null int64\n",
      "workclass          32561 non-null object\n",
      "fnlwgt             32561 non-null int64\n",
      "education          32561 non-null object\n",
      "edu_num            32561 non-null int64\n",
      "marital_status     32561 non-null object\n",
      "occupation         32561 non-null object\n",
      "relationship       32561 non-null object\n",
      "race               32561 non-null object\n",
      "sex                32561 non-null object\n",
      "cap_gain           32561 non-null int64\n",
      "cap_loss           32561 non-null int64\n",
      "work_hrs_weekly    32561 non-null int64\n",
      "country            32561 non-null object\n",
      "income             32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workclass          0\n",
       "fnlwgt             0\n",
       "education          0\n",
       "edu_num            0\n",
       "marital_status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "sex                0\n",
       "cap_gain           0\n",
       "cap_loss           0\n",
       "work_hrs_weekly    0\n",
       "country            0\n",
       "income             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_dummies(X):\n",
    "    \n",
    "    #Initialize Empty DataFrame\n",
    "    df_preprocess = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    #Identify Categorical Variables\n",
    "    cols_interest = [c for c in X.columns if 'income' not in c]\n",
    "    \n",
    "    #Iterate over Columns and Convert to Dummy Variables\n",
    "    for c,r in X[cols_interest].iteritems():\n",
    "        if r.dtype == object:\n",
    "            r = pd.get_dummies(r,prefix=c)\n",
    "        #join to one dataframe\n",
    "        df_preprocess = df_preprocess.join(r)\n",
    "    \n",
    "    #Add Target Variable back to DataFrame\n",
    "    df_out = pd.concat([X['income'],df_preprocess],axis=1)\n",
    "    return(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df_train,df_test):\n",
    "    \n",
    "    #Missing values are denoted by '?' - replace with the missing data with NaNs\n",
    "    def replace_nans(df):\n",
    "        for c in df.columns:\n",
    "            df[c] = df[c].replace(to_replace=' ?',value=np.nan)\n",
    "        return(df)\n",
    "            \n",
    "    df_train = replace_nans(df_train).dropna().reset_index(drop=True)  \n",
    "    df_test = replace_nans(df_test).dropna().reset_index(drop=True)\n",
    "    \n",
    "    #Remove ending '.' for test.income \n",
    "    try:\n",
    "        df_test['income'] = df_test['income'].apply(lambda x: x.strip('.'))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Remove any whitespace\n",
    "    cat_variables = [c for c,r in df_train.iteritems() if r.dtype == object]\n",
    "    for col in cat_variables:\n",
    "        df_train[col] = df_train[col].str.strip()\n",
    "        df_test[col] = df_test[col].str.strip()\n",
    "    \n",
    "    #Standardize Numerical Values\n",
    "    num_variables = [c for c,r in df_train.iteritems() if r.dtype == int and c not in ['income']]\n",
    "    for c in num_variables:\n",
    "        std = MinMaxScaler().fit(df_train[c].astype(np.float32).values.reshape(-1,1))\n",
    "        df_train[c] = std.transform(df_train[c].astype(np.float32).values.reshape(-1,1))\n",
    "        df_test[c] = std.transform(df_test[c].astype(np.float32).values.reshape(-1,1))\n",
    "        \n",
    "    #One-Hot Encoding for Categorical Variables\n",
    "    df_train = convert_to_dummies(df_train)\n",
    "    df_test = convert_to_dummies(df_test)\n",
    "                       \n",
    "    #Setup encoder for 'income' variable\n",
    "    tmp = LabelEncoder()\n",
    "    df_train['income'] = tmp.fit_transform(df_train['income'])\n",
    "    df_test['income'] = tmp.transform(df_test['income'])\n",
    "    \n",
    "    return(df_train,df_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train,df_test = preprocess(df_train_raw,df_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Nerual Network using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf #entire api\n",
    "from tensorflow.contrib import learn #get access to many wrappers\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.learn import SKCompat #similar interfaces used in sklearn\n",
    "tf.logging.set_verbosity(tf.logging.WARN) # control the verbosity of tensor flow\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Nerual_Network(features, targets, mode):\n",
    "\n",
    "    \"\"\" Build Deep Neural Net -- return predictions, loss, training_op\n",
    "    \n",
    "    Keyword arguments:\n",
    "    \n",
    "    dict_features: input features\n",
    "    target: target features\n",
    "    mode: \n",
    "    \"\"\"\n",
    "    \n",
    "    # =====SETUP ARCHITECTURE=====\n",
    "    #One hidden layer with RELU activation\n",
    "    features = layers.relu(features, num_outputs=50) \n",
    "    #Fully Connected Layer with 1 output\n",
    "    features = layers.fully_connected(features, num_outputs=100) \n",
    "    #Second Fully Connected Layer\n",
    "    features = layers.fully_connected(features, num_outputs=1) \n",
    "    #Pass through a sigmoid activation\n",
    "    output_layer = tf.sigmoid(features) \n",
    "    #Reshape the output to be one dimensional\n",
    "    predictions = tf.reshape(output_layer, [-1])\n",
    "\n",
    "    loss_mse = None\n",
    "    train_op = None\n",
    "    \n",
    "    # Calculate Loss\n",
    "    if mode != learn.ModeKeys.INFER:\n",
    "        # =====LOSS=======\n",
    "        #using MSE as loss function\n",
    "        loss_mse = tf.losses.mean_squared_error(targets, predictions) \n",
    "    \n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        # =====OPTIMIZER PARAMS========\n",
    "        train_op = layers.optimize_loss(\n",
    "            loss=loss_mse, \n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            optimizer='Adagrad', \n",
    "            learning_rate=0.1)\n",
    "    \n",
    "    #Prediction Threshold\n",
    "    predictions_out = predictions>0.5\n",
    "    \n",
    "    model = model_fn_lib.ModelFnOps(mode=mode, predictions={ \n",
    "        'incomes':predictions_out}, loss=loss_mse, train_op=train_op)\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = df_train.ix[:,1:].astype(np.float32).values\n",
    "target = df_train.ix[:,0].astype(np.float32).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/ky/49p8hmz15hxchr2k1kvm6thm0000gn/T/tmp7i_hcut8\n",
      "WARNING:tensorflow:From <timed exec>:2: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <timed exec>:2: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "CPU times: user 2min 36s, sys: 10.4 s, total: 2min 47s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "clf = learn.Estimator(model_fn=Nerual_Network)\n",
    "clf.fit(features,target,steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = df_test.astype(np.float32).values\n",
    "y_test = df_test['income'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-d76f43a7b59d>:1: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "[[10752   608]\n",
      " [ 3601    99]] 0.720517928287\n"
     ]
    }
   ],
   "source": [
    "yhat = clf.predict(l)\n",
    "yhat = [x['incomes'] for x in yhat]\n",
    "print(confusion_matrix(y_test,yhat),accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
